{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znDJCOlOqLiR"
      },
      "outputs": [],
      "source": [
        "pip install -q penquins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yqa7BzZ4qCwy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pdb\n",
        "import json\n",
        "from penquins import Kowalski\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9u37c4a2qHRF"
      },
      "outputs": [],
      "source": [
        "def get_highscoring_objects(otype='vnv',condition=\"$or\",\n",
        "    limit=0.9,limit_dnn=None,limit_xgb=None,):\n",
        "\n",
        "    if limit_dnn == None:\n",
        "        limit_dnn = limit\n",
        "    if limit_xgb == None:\n",
        "        limit_xgb = limit\n",
        "\n",
        "    ### example\n",
        "    q = {\"query_type\": \"find\",\n",
        "             \"query\": {\n",
        "                 \"catalog\": \"ZTF_source_classifications_DR5\",\n",
        "                 \"filter\": { condition : [{'%s_xgb' %otype: { '$gt': limit_xgb }},\n",
        "                                    {'%s_dnn' %otype: { '$gt': limit_dnn }}],\n",
        "                           },\n",
        "                 \"projection\": {}\n",
        "             },\n",
        "             \"kwargs\": {     }\n",
        "             }\n",
        "\n",
        "    r = G.query(q)\n",
        "\n",
        "    return pd.DataFrame(r['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "swBQEDm8qaWK"
      },
      "outputs": [],
      "source": [
        "def get_stats(ids):\n",
        "    qs = [\n",
        "           {\"query_type\": \"find\",\n",
        "             \"query\": {\n",
        "                 \"catalog\": \"ZTF_source_features_DR5\",\n",
        "                 \"filter\": {'_id': i\n",
        "                            },\n",
        "                 \"projection\": {}\n",
        "             },\n",
        "             \"kwargs\": {     }\n",
        "             }\n",
        "        for i in ids\n",
        "    ]\n",
        "    rs = G.batch_query(qs, n_treads=32)\n",
        "\n",
        "    return pd.DataFrame([s['data'][0] for s in rs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6MfNrTKGYe04"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "trainingset = pd.read_csv('dataset.d15.csv')\n",
        "\n",
        "# Kowalski\n",
        "with open('password.txt', 'r') as f:\n",
        "    password = f.read().splitlines()\n",
        "G = Kowalski(username=password[0], password=password[1], host='gloria.caltech.edu', timeout=1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get scores and data and combine\n",
        "scores = get_highscoring_objects(otype='vnv',condition='$or')"
      ],
      "metadata": {
        "id": "GOI50XfqBlw1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = scores.index\n",
        "condition = ((scores[\"vnv_dnn\"]>0.95)&(scores['vnv_xgb']<=0.1)) | ((scores[\"vnv_dnn\"]<=0.1)&(scores['vnv_xgb']>0.95))\n",
        "disagreements = index[condition]\n",
        "disagreeing_scores = scores.iloc[disagreements,:]\n",
        "disagreeing_scores"
      ],
      "metadata": {
        "id": "_z5GJrsebzCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uud3KewsgzXj"
      },
      "outputs": [],
      "source": [
        "stats = get_stats(disagreeing_scores['_id'])\n",
        "data = pd.merge(disagreeing_scores,stats,left_on='_id',right_on='_id')\n",
        "data['train'] = np.isin(data['_id'],trainingset['ztf_id'])\n",
        "sample = data[~data['train']]\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l1yvcI8Nqgai"
      },
      "outputs": [],
      "source": [
        "def upload():\n",
        "    import requests\n",
        "    token = \"9f78fcea-61f0-4b71-8b9f-d1b1b573fd4d\" # Jason's Fritz token\n",
        "\n",
        "    def api(method, endpoint, data=None):\n",
        "        headers = {'Authorization': f'token {token}'}\n",
        "        response = requests.request(method, endpoint, json=data, headers=headers)\n",
        "        return response\n",
        "\n",
        "\n",
        "    headers={\"Authorization\": f\"token {token}\"}\n",
        "\n",
        "    for index, row in sample.iterrows():\n",
        "        #print(row)\n",
        "        i = row['_id']\n",
        "        period = row['period']\n",
        "        \n",
        "        # upload \n",
        "        json = { \"catalog\": \"ZTF_sources_20210401\",\n",
        "                  \"group_ids\": [371]} #group id for the upload location\n",
        "        json['light_curve_ids'] = [int(i)]\n",
        "        response = requests.post(\n",
        "          url='https://fritz.science/api/archive',\n",
        "          json=json,\n",
        "          headers=headers,)\n",
        "\n",
        "        # get objid\n",
        "        try:\n",
        "            obj_id = response.json()['data']['obj_id']\n",
        "        except:\n",
        "            print('failed to upload target')\n",
        "            continue\n",
        "\n",
        "        print(obj_id)\n",
        "\n",
        "        # annotate\n",
        "        url = 'https://fritz.science/api/sources/%s/annotations' %obj_id\n",
        "        json = { \"origin\": \"ML_DR5_d15_v1\",\n",
        "              \"group_ids\": [348]}\n",
        "        \n",
        "        Gaia = {'Plx': row['Gaia_EDR3__parallax'],'Mag_G': row['Gaia_EDR3__phot_g_mean_mag'],'Mag_Bp': row['Gaia_EDR3__phot_bp_mean_mag'],'Mag_Rp': row['Gaia_EDR3__phot_rp_mean_mag']}\n",
        "\n",
        "        json['data'] = {'period': row['period'] , \n",
        "                        'vnv': {'vnv_dnn': np.round(row['vnv_dnn'],3),  'vnv_xgb': np.round(row['vnv_xgb'],3)},\n",
        "                        'Gaia': Gaia}\n",
        "\n",
        "        response = requests.post(\n",
        "          url=url,\n",
        "          json=json,\n",
        "          headers=headers,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3s1NDCBrFBZ"
      },
      "outputs": [],
      "source": [
        "upload()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SCOPE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}